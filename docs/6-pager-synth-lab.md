# Synth-Lab: Acelerando Experimenta√ß√£o de Produto atrav√©s de Pesquisa Sint√©tica

## 1. Introduction

### Contexto
Vivemos um momento √∫nico na hist√≥ria do desenvolvimento de produtos. A intelig√™ncia artificial n√£o apenas reduziu drasticamente o tempo de cria√ß√£o de POCs (de meses para semanas), mas tamb√©m democratizou a capacidade de experimentar ideias rapidamente. Por√©m, identificamos um paradoxo: **embora possamos construir mais r√°pido, ainda demoramos semanas para validar se devemos construir**.

O processo tradicional de pesquisa com usu√°rios ‚Äî recrutamento, agendamento, condu√ß√£o de entrevistas, an√°lise qualitativa ‚Äî consome 2-4 semanas e custa entre R$20-80 mil por ciclo. Para an√°lises quantitativas, amostras de 20-50 usu√°rios oferecem poder estat√≠stico limitado. Resultado: equipes lan√ßam features baseadas em hip√≥teses n√£o validadas, descobrindo problemas de ado√ß√£o apenas ap√≥s meses de desenvolvimento.

### Oportunidade
Se a IA pode acelerar a constru√ß√£o, **por que n√£o pode acelerar a investiga√ß√£o?** Synth-Lab nasce dessa pergunta. N√£o buscamos substituir pesquisa com usu√°rios reais, mas sim **reduzir drasticamente o tempo de prepara√ß√£o de experimentos** e **direcionar melhor as investiga√ß√µes** que ser√£o executadas com usu√°rios.

### Prop√≥sito do Documento
Este documento apresenta a estrat√©gia, estado atual e prioridades do Synth-Lab ‚Äî uma plataforma brasileira de pesquisa sint√©tica que permite equipes de produto executarem experimentos qualitativos e quantitativos em horas, n√£o semanas, atrav√©s de personas sint√©ticas baseadas em dados demogr√°ficos reais do IBGE.

---

## 2. Goals: M√©tricas de Sucesso

### M√©tricas Prim√°rias (North Star)

| M√©trica | Defini√ß√£o | Meta 2026 Q2 | Situa√ß√£o Atual |
|---------|-----------|--------------|----------------|
| **Time-to-Insight** | Tempo m√©dio da hip√≥tese at√© insights acion√°veis | **< 4 horas** | 2-4 semanas (baseline tradicional) |
| **Cost per Experiment** | Custo total de um ciclo completo de valida√ß√£o | **< R$ 200** | R$ 20-80 mil (baseline tradicional) |
| **Iteration Velocity** | N√∫mero de experimentos executados por equipe/trimestre | **> 15 experimentos** | 1-2 experimentos (baseline tradicional) |

### M√©tricas Secund√°rias (Product Health)

| M√©trica | Defini√ß√£o | Meta 2026 Q2 |
|---------|-----------|--------------|
| **Synth Diversity Score** | Cobertura de arqu√©tipos √∫nicos gerados (Shannon Entropy) | > 4.5 bits |
| **Research Completion Rate** | % de entrevistas UX completadas sem falhas | > 95% |
| **Simulation Accuracy** | Correla√ß√£o entre simula√ß√£o e outcomes reais (quando dispon√≠vel) | > 0.70 (Pearson r) |
| **Exploration Success Rate** | % de explora√ß√µes que encontram solu√ß√µes melhores que baseline | > 60% |
| **User Satisfaction (NPS)** | Recomenda√ß√£o de PMs/UX Researchers | > 50 |

### M√©tricas de Ado√ß√£o (Business)

| M√©trica | Defini√ß√£o | Meta 2026 Q4 |
|---------|-----------|--------------|
| **Active Teams** | Equipes executando ‚â• 1 experimento/m√™s | 10 equipes |
| **Experiments Executed** | Total de experimentos criados e analisados | 500 experimentos |
| **Features De-risked** | Features validadas antes de entrar em desenvolvimento | 150 features |
| **Roadmap Impact** | % de decis√µes de roadmap influenciadas por Synth-Lab | > 40% |

### Crit√©rios de Sucesso Qualitativos
1. PMs usam Synth-Lab **antes** de escrever especifica√ß√µes t√©cnicas
2. UX Researchers citam insights de synths em research reports
3. Executivos referenciam simula√ß√µes em decis√µes de go/no-go
4. Engenheiros consultam scorecards de complexidade durante planning

---

## 3. Tenets: Princ√≠pios de Neg√≥cio

### 1. Simula√ß√£o Direciona, N√£o Substitui
**"Synths aceleram investiga√ß√£o, mas decis√µes finais exigem valida√ß√£o com humanos reais."**

- Tratamos simula√ß√µes como sinalizadores de risco, n√£o como verdades absolutas
- Sempre recomendamos valida√ß√£o com usu√°rios reais antes de grandes investimentos
- Transpar√™ncia sobre limita√ß√µes: synths n√£o capturam toda complexidade humana
- **Trade-off aceito**: Preferimos direcionar bem 80% das investiga√ß√µes a ter 100% de precis√£o em 20% delas

### 2. Dados Brasileiros, Personas Brasileiras
**"A diversidade do Brasil n√£o cabe em modelos gen√©ricos de outros pa√≠ses."**

- Todas as distribui√ß√µes demogr√°ficas baseadas em dados IBGE (Censo 2022, PNAD Cont√≠nua)
- Arqu√©tipos refletem realidades regionais: desigualdade, diversidade cultural, barreiras digitais
- Vi√©s expl√≠cito: priorizamos representatividade brasileira sobre generaliza√ß√µes globais
- **Trade-off aceito**: Menor aplicabilidade internacional em favor de maior precis√£o local

### 3. Velocidade com Rigor
**"Insights em horas, mas com metodologia cient√≠fica."**

- Monte Carlo com 1000-10.000 execu√ß√µes (n√£o 10-20 como em testes A/B prematuros)
- An√°lises estat√≠sticas completas: SHAP, PDP, clustering, outlier detection
- Rastreabilidade: todo resultado rastre√°vel at√© prompts, seeds, par√¢metros
- **Trade-off aceito**: Lat√™ncia de alguns minutos para garantir robustez estat√≠stica

### 4. IA Aumenta, N√£o Automatiza Decis√µes
**"LLMs prop√µem, humanos decidem."**

- Explora√ß√µes de cen√°rio oferecem m√∫ltiplas alternativas (beam search), n√£o uma √∫nica resposta
- Insights de charts s√£o hip√≥teses para investiga√ß√£o, n√£o conclus√µes definitivas
- PMs mant√™m controle total: podem rejeitar, ajustar ou refinar qualquer sugest√£o da IA
- **Trade-off aceito**: Mais intera√ß√£o humana necess√°ria, mas com melhor alinhamento estrat√©gico

### 5. C√≥digo Aberto, Transpar√™ncia Total
**"Confian√ßa vem de entender como resultados s√£o gerados."**

- Prompts de LLM vis√≠veis no c√≥digo-fonte
- Modelos probabil√≠sticos documentados e audit√°veis
- Rastreamento OpenTelemetry de todas chamadas LLM (Phoenix)
- **Trade-off aceito**: Possibilidade de c√≥pia por concorrentes, mas ganho em confiabilidade

---

## 4. State of the Business: Situa√ß√£o Atual

### 4.1 Status de Implementa√ß√£o

#### Componentes Core (‚úÖ Produ√ß√£o)
- **Gera√ß√£o de Synths**: 1.800 personas/segundo, 80+ atributos, avatares visuais
- **Motor de Simula√ß√£o**: Monte Carlo com 10.000 execu√ß√µes, cache de resultados
- **Entrevistas UX**: Sistema de 2 agentes (entrevistador + synth), streaming SSE
- **An√°lise Quantitativa**: SHAP, PDP, clustering, outlier detection, 12 tipos de charts
- **Explora√ß√£o de Cen√°rios**: Beam search com filtragem Pareto, at√© 5 n√≠veis de profundidade
- **Banco de Dados**: PostgreSQL com 12 tabelas, Alembic migrations
- **API REST**: 17 endpoints FastAPI, documenta√ß√£o OpenAPI
- **Observabilidade**: Rastreamento Phoenix/OpenTelemetry de todas chamadas LLM

#### Features Recentes (üÜï √öltimas 4 semanas)
- Sistema de gera√ß√£o de resumos de explora√ß√£o (spec 028)
- Insights de IA para cada tipo de chart (spec 023)
- Migra√ß√£o SQLite ‚Üí PostgreSQL (spec 027)
- Sistema de documentos (summaries, PR-FAQs, executive reports)
- Frontend React com TanStack Query e shadcn/ui

#### Em Desenvolvimento (üöß Sprint Atual)
- Visualiza√ß√£o de √°rvores de explora√ß√£o no frontend
- Gera√ß√£o de PR-FAQs para explora√ß√µes
- Sistema de resumos executivos para simula√ß√µes
- Testes de contrato da API (contract tests)

#### Backlog Priorizado (üìã Pr√≥ximos 2 meses)
- Sistema de feedback: usu√°rios marcam insights √∫teis/n√£o √∫teis
- Compara√ß√£o lado-a-lado de experimentos (A/B testing de features)
- Exporta√ß√£o de dados brutos (CSV, JSON) para an√°lises customizadas
- Integra√ß√£o com ferramentas de roadmap (Jira, Linear, Notion)
- Dashboard de m√©tricas agregadas (uso, custos LLM, taxa de sucesso)

### 4.2 Capacidades T√©cnicas Atuais

| Dimens√£o | Capacidade | Limita√ß√£o |
|----------|------------|-----------|
| **Synth Generation** | 1.800 synths/segundo | Limitado por taxa de API OpenAI para avatares |
| **Concurrent Interviews** | 12 entrevistas simult√¢neas | Semaphore configur√°vel, padr√£o = 12 |
| **Simulation Scale** | 10.000 execu√ß√µes em ~2min | Performance degrada com > 50K execu√ß√µes |
| **LLM Throughput** | ~30 requisi√ß√µes/min (gpt-4o-mini) | Rate limits OpenAI Tier 2 |
| **Database Size** | Testado com 10K synths, 100 experimentos | N√£o testado com > 1M registros |
| **API Latency (p95)** | < 200ms (exceto endpoints de IA) | Endpoints com LLM: 5-30s |

### 4.3 Arquitetura de Custos (Estimativa por Experimento)

```
Experimento Completo (Baseline Analysis + UX Research):
‚îú‚îÄ‚îÄ Gera√ß√£o de 1.000 Synths
‚îÇ   ‚îî‚îÄ‚îÄ Avatares (DALL-E 3): ~$0.40 (0.040 * 10 amostras)
‚îú‚îÄ‚îÄ Simula√ß√£o Monte Carlo (10.000 execu√ß√µes)
‚îÇ   ‚îî‚îÄ‚îÄ Processamento: $0.00 (sem custos LLM)
‚îú‚îÄ‚îÄ An√°lise Quantitativa (12 charts + insights)
‚îÇ   ‚îî‚îÄ‚îÄ LLM Insights (gpt-4o-mini): ~$0.15 (12 * 1K tokens out)
‚îú‚îÄ‚îÄ Entrevistas UX (10 synths, 6 turnos cada)
‚îÇ   ‚îî‚îÄ‚îÄ LLM Conversations: ~$1.50 (60 turnos * 500 tokens avg)
‚îú‚îÄ‚îÄ Resumo + PR-FAQ
‚îÇ   ‚îî‚îÄ‚îÄ LLM Synthesis: ~$0.30 (3K tokens out)
‚îî‚îÄ‚îÄ TOTAL: ~$2.35 USD (~R$ 12 BRL)

Explora√ß√£o de Cen√°rio (5 n√≠veis, beam width = 3):
‚îú‚îÄ‚îÄ LLM Proposals: ~15 chamadas (1-2 por n√≥)
‚îÇ   ‚îî‚îÄ‚îÄ ~$0.50 (15 * 2K tokens avg)
‚îú‚îÄ‚îÄ Simula√ß√µes: ~15 n√≥s * 1.000 exec cada
‚îÇ   ‚îî‚îÄ‚îÄ $0.00 (sem custos LLM)
‚îú‚îÄ‚îÄ Resumo de Explora√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ ~$0.20 (1.5K tokens out)
‚îî‚îÄ‚îÄ TOTAL ADICIONAL: ~$0.70 USD (~R$ 3.50 BRL)

CUSTO TOTAL EXPERIMENTO COMPLETO: < R$ 20 BRL
```

### 4.4 Casos de Uso Validados (Internos)

Executamos 8 experimentos internos para validar a plataforma:

| Experimento | Tipo | Insight Principal | Tempo |
|-------------|------|-------------------|-------|
| **Onboarding Gamificado** | Qualitativo + Quantitativo | Synths com baixa escolaridade rejeitaram mec√¢nicas complexas ‚Üí simplificar tutorial | 3h |
| **Checkout em 1 Clique** | Quantitativo | Simula√ß√£o mostrou 18% de abandono por falta de confian√ßa em seguran√ßa | 1.5h |
| **Dashboard de Analytics** | Explora√ß√£o | LLM prop√¥s 3 caminhos, vencedor: remover 40% das m√©tricas + tour guiado | 4h |
| **Feature de Compartilhamento** | Qualitativo | Entrevistas revelaram preocupa√ß√£o com privacidade em 7/10 synths | 2h |
| **Modo Offline** | Quantitativo | SHAP mostrou que lat√™ncia de rede (n√£o complexidade UI) prediz abandono | 2.5h |
| **Notifica√ß√µes Push** | Explora√ß√£o + UX | Explora√ß√£o sugeria opt-in agressivo, UX interviews mostraram rejei√ß√£o ‚Üí opt-in suave | 5h |
| **Sistema de Recomenda√ß√£o** | Quantitativo | Clustering identificou 4 perfis distintos, cada um precisa de l√≥gica diferente | 3h |
| **Wizard Multi-Step** | Explora√ß√£o | 5 n√≠veis de explora√ß√£o reduziram scorecard de 8.5 ‚Üí 4.2 (complexidade) | 4h |

**Taxa de Sucesso Interna**: 7/8 experimentos geraram insights acion√°veis (87.5%)

### 4.5 Gaps e D√≠vidas T√©cnicas

#### Gaps Funcionais
1. **Falta de Feedback Loop**: N√£o sabemos se insights de IA foram √∫teis (sem sistema de ratings)
2. **Sem Compara√ß√£o A/B**: Imposs√≠vel comparar 2 experimentos lado-a-lado visualmente
3. **Sem Versionamento de Experimentos**: Editar experimento sobrescreve, sem hist√≥rico
4. **Sem Permiss√µes/Multi-tenancy**: Todos podem ver/editar tudo (bloqueador para produ√ß√£o multi-empresa)
5. **Visualiza√ß√£o de Explora√ß√£o Limitada**: √Årvore de cen√°rios n√£o renderizada no frontend

#### D√≠vidas T√©cnicas
1. **Testes de Integra√ß√£o Limitados**: 60% de cobertura, falta testar workflows end-to-end
2. **Sem Rate Limiting**: API vulner√°vel a DDoS ou uso abusivo
3. **Sem Retry Logic**: Falhas de LLM n√£o fazem retry autom√°tico
4. **Cache N√£o Invalidado**: Editar experimento n√£o limpa cache de charts
5. **Sem Monitoramento de Custos**: N√£o rastreamos gasto por experimento/usu√°rio

#### Escalabilidade
1. **Batch Processing**: Entrevistas executam sequencialmente em lotes (semaphore), n√£o totalmente paralelas
2. **Database Indexing**: Faltam √≠ndices compostos para queries complexas (explorations + nodes)
3. **Frontend State**: Sem persist√™ncia local (refreshes perdem estado)

---

## 5. Lessons Learned: Aprendizados

### 5.1 O Que Funcionou Bem

#### 1. LLMs como Entrevistadores S√£o Surpreendentemente Eficazes
**Descoberta**: Conversas entre 2 LLMs (entrevistador + synth) geram transcri√ß√µes com profundidade compar√°vel a entrevistas juniores reais.

- **Evid√™ncia**: Em testes cegos, 3 UX researchers n√£o conseguiram distinguir transcritos de synths vs. humanos em 6/10 casos
- **Por qu√™ funciona**: Structured outputs do OpenAI garantem respostas no personagem; function calling permite mostrar imagens/PDFs
- **Aprendizado**: Qualidade depende criticamente do prompt do entrevistador ‚Äî scripts vagos geram entrevistas rasas

#### 2. Monte Carlo Revela Padr√µes Invis√≠veis em Amostras Pequenas
**Descoberta**: Simula√ß√µes com 10.000 execu√ß√µes exp√µem intera√ß√µes n√£o-lineares que 20-50 usu√°rios reais nunca mostrariam.

- **Evid√™ncia**: Experimento "Modo Offline" ‚Äî SHAP revelou que lat√™ncia de rede + idade > 55 anos tinha efeito multiplicativo (n√£o aditivo) no abandono
- **Por qu√™ funciona**: Amostragem probabil√≠stica cobre cauda longa da distribui√ß√£o; SHAP captura intera√ß√µes de 2¬™ ordem
- **Aprendizado**: Explicabilidade (SHAP/PDP) √© t√£o importante quanto o resultado da simula√ß√£o

#### 3. Beam Search com LLM Supera Busca Exaustiva
**Descoberta**: Explora√ß√£o dirigida por IA (beam width = 3) encontra solu√ß√µes 40% melhores que busca aleat√≥ria em 1/10 do tempo.

- **Evid√™ncia**: Experimento "Dashboard Analytics" ‚Äî 15 n√≥s explorados (5 n√≠veis) vs. 200+ combina√ß√µes poss√≠veis de features
- **Por qu√™ funciona**: LLM aprende com scores de itera√ß√µes anteriores (via prompt com hist√≥rico); Pareto filtering elimina ramos dominados
- **Aprendizado**: Largura do beam (3-5) importa mais que profundidade (> 5 n√≠veis tem retorno decrescente)

#### 4. Dados Demogr√°ficos IBGE S√£o Suficientes para Diversidade
**Descoberta**: 80+ atributos baseados em IBGE geram 10.000+ arqu√©tipos distintos sem precisar de dados comportamentais propriet√°rios.

- **Evid√™ncia**: Shannon Entropy = 4.7 bits (pr√≥ximo do m√°ximo te√≥rico 4.8 para 27 dimens√µes categ√≥ricas)
- **Por qu√™ funciona**: Distribui√ß√µes correlacionadas (idade √ó regi√£o √ó renda √ó escolaridade) criam combina√ß√µes naturalmente diversas
- **Aprendizado**: Defici√™ncias (visual, auditiva, motora) e vieses cognitivos s√£o diferenciadores-chave ‚Äî sem eles, synths ficam gen√©ricos

### 5.2 O Que N√£o Funcionou (e Por Qu√™)

#### 1. Scorecards Autom√°ticos por LLM S√£o Inconsistentes
**Problema**: Pedir ao LLM para estimar complexidade/esfor√ßo/risco de features gerou varia√ß√µes de ¬±30% entre execu√ß√µes id√™nticas.

- **Tentativa**: `gpt-4o-mini` com prompt estruturado + few-shot examples
- **Resultado**: Mesma feature recebia scores 6.5, 4.2, 7.8 em 3 execu√ß√µes consecutivas (seed fixo n√£o ajudou)
- **Raiz do problema**: LLMs n√£o t√™m "mem√≥ria de calibra√ß√£o" ‚Äî sem contexto comparativo, cada avalia√ß√£o √© isolada
- **Solu√ß√£o adotada**: Scorecards agora s√£o **input manual** do PM, com op√ß√£o de sugest√£o LLM (n√£o autom√°tico)
- **Aprendizado**: LLMs s√£o melhores em compara√ß√µes relativas ("A √© mais complexo que B") do que avalia√ß√µes absolutas

#### 2. Simula√ß√µes com Modelos Causais Expl√≠citos Falharam
**Problema**: Tentamos usar Bayesian Networks para modelar rela√ß√µes causais entre atributos de synths ‚Üí outcomes. Modelos n√£o convergiam.

- **Tentativa**: `pgmpy` com estruturas definidas manualmente (DAGs) e aprendizado de par√¢metros via Maximum Likelihood
- **Resultado**: 80% dos experimentos geravam probabilidades degeneradas (P = 0 ou 1), sem nuance
- **Raiz do problema**: Dados sint√©ticos n√£o t√™m varia√ß√£o suficiente para aprender estruturas causais complexas
- **Solu√ß√£o adotada**: Voltamos para **modelos probabil√≠sticos manuais** (feature_extraction.py) com fun√ß√µes handcrafted
- **Aprendizado**: Para synths, modelos simples e interpret√°veis > modelos complexos e opacos

#### 3. Frontend com Server-Side Rendering Foi Abandonado
**Problema**: Primeira vers√£o usava Next.js com SSR para SEO. Lat√™ncia de API (5-30s) tornava UX insuport√°vel.

- **Tentativa**: Next.js 14 App Router com Server Components e React Suspense
- **Resultado**: Usu√°rios viam spinners por 20s esperando simula√ß√µes completarem; sem feedback incremental
- **Raiz do problema**: SSR quebra streaming de resultados progressivos (ex: simula√ß√£o em tempo real)
- **Solu√ß√£o adotada**: **Client-Side SPA** com React + TanStack Query + SSE para streaming
- **Aprendizado**: Para aplica√ß√µes de IA com lat√™ncias longas, CSR + streaming > SSR

#### 4. Entrevistas com > 10 Turnos Ficam Repetitivas
**Problema**: Tentamos entrevistas longas (15-20 turnos) para profundidade. LLM come√ßava a se repetir ap√≥s turno 8-10.

- **Tentativa**: Aumentar max_turns de 6 ‚Üí 20, adicionar instru√ß√µes de "evite repeti√ß√£o"
- **Resultado**: Turnos 11-20 eram varia√ß√µes superficiais de turnos anteriores, sem novos insights
- **Raiz do problema**: LLMs t√™m "recency bias" ‚Äî depois de certo ponto, contexto inicial do synth se perde
- **Solu√ß√£o adotada**: Limite padr√£o = **6 turnos**, com op√ß√£o de 10 para casos espec√≠ficos
- **Aprendizado**: M√∫ltiplas entrevistas curtas (6 turnos √ó 10 synths) > 1 entrevista longa (20 turnos √ó 3 synths)

### 5.3 Surpresas Positivas

#### 1. PMs Usam Explora√ß√µes para Negociar com Stakeholders
**Observa√ß√£o**: Em 4/8 experimentos internos, PMs exportaram PDFs de explora√ß√£o para justificar decis√µes de descope.

- **Caso**: Experiment "Dashboard Analytics" ‚Äî PM mostrou que remover 40% das m√©tricas aumentava sucesso de 28% ‚Üí 41%
- **Impacto**: Stakeholder aceitou descope sem resist√™ncia, algo incomum
- **Insight**: Simula√ß√µes d√£o "cobertura objetiva" para decis√µes dif√≠ceis

#### 2. Entrevistas de Synths Geram Hip√≥teses N√£o Planejadas
**Observa√ß√£o**: 5/8 experimentos tiveram insights n√£o relacionados √† hip√≥tese original.

- **Caso**: Experiment "Checkout em 1 Clique" ‚Äî entrevistas revelaram confus√£o sobre cancelamento de assinatura (n√£o estava no topic guide)
- **Impacto**: Equipe adicionou FAQ sobre cancelamento no onboarding
- **Insight**: Conversas abertas > question√°rios estruturados para descoberta

#### 3. Visualiza√ß√µes de SHAP S√£o Mais Persuasivas que Tabelas
**Observa√ß√£o**: Charts de SHAP/PDP receberam 3x mais compartilhamentos internos que tabelas de success_rate.

- **M√©trica**: 24 compartilhamentos de SHAP charts vs. 8 de tabelas num√©ricas (via Slack analytics)
- **Hip√≥tese**: Visualiza√ß√µes contam hist√≥rias; tabelas exigem interpreta√ß√£o
- **A√ß√£o**: Priorizamos gera√ß√£o autom√°tica de charts sobre relat√≥rios textuais

---

## 6. Strategic Priorities: Prioridades Estrat√©gicas

### Horizonte de 6 Meses (2026 Q1-Q2)

#### **Prioridade 1: Validar Product-Market Fit com 3 Equipes Piloto**
**Objetivo**: Provar que Synth-Lab muda comportamento de tomada de decis√£o em organiza√ß√µes reais.

**T√°ticas**:
1. **Recrutar 3 Equipes Beta (Jan-Fev 2026)**
   - **Perfil alvo**: Startups S√©rie A-B com 5-15 pessoas de produto
   - **Crit√©rio de sele√ß√£o**: Fazem research trimestral, t√™m or√ßamento para ferramentas
   - **Proposta de valor**: 3 meses gratuitos + suporte dedicado (1h/semana) em troca de feedback estruturado
   - **Entreg√°vel**: 3 equipes assinadas, cada uma comprometida com ‚â• 5 experimentos

2. **Implementar Sistema de Feedback In-App (Jan 2026)**
   - **Feature**: Thumbs up/down em cada insight gerado por IA
   - **M√©trica de sucesso**: > 70% de insights marcados como √∫teis
   - **A√ß√£o em caso de falha**: Se < 50%, redesenhar prompts de gera√ß√£o de insights
   - **Entreg√°vel**: Dashboard de quality score por tipo de insight

3. **Instrumentar Funil de Ado√ß√£o (Fev 2026)**
   - **Eventos rastreados**:
     - Experimento criado ‚Üí Simula√ß√£o executada ‚Üí Insights visualizados ‚Üí Exporta√ß√£o PDF ‚Üí Decis√£o tomada (survey)
   - **Objetivo**: Identificar onde usu√°rios abandonam
   - **Entreg√°vel**: Mixpanel/Amplitude configurado, relat√≥rio semanal de convers√£o

4. **Conduzir 6 Entrevistas de Valida√ß√£o (Mar 2026)**
   - **Perguntas-chave**:
     - Synth-Lab mudou alguma decis√£o de roadmap? Qual?
     - Voc√™ validou insights de synths com usu√°rios reais? Qu√£o alinhados estavam?
     - Pagaria R$ 500/m√™s por essa ferramenta? Por qu√™ sim/n√£o?
   - **Entreg√°vel**: Report de valida√ß√£o com recomenda√ß√µes de pricing e posicionamento

**Crit√©rio de Sucesso (Go/No-Go para Prioridade 2)**:
- ‚â• 2/3 equipes executaram 5+ experimentos
- ‚â• 1 equipe relata mudan√ßa concreta de roadmap devido a Synth-Lab
- Taxa de insights √∫teis (thumbs up) > 60%

---

#### **Prioridade 2: Escalar Capacidade de Gera√ß√£o de Insights**
**Objetivo**: Reduzir tempo de Time-to-Insight de 4h ‚Üí 1h atrav√©s de automa√ß√£o e otimiza√ß√£o.

**T√°ticas**:
1. **Paralelizar An√°lises de Charts (Jan 2026)**
   - **Problema atual**: 12 charts gerados sequencialmente (12 √ó 15s = 3min)
   - **Solu√ß√£o**: `asyncio.gather()` para gerar todos insights simultaneamente
   - **Ganho esperado**: 3min ‚Üí 20s (85% redu√ß√£o)
   - **Entreg√°vel**: PR com refactor de `insight_service.py`

2. **Implementar Cache Inteligente de Simula√ß√µes (Fev 2026)**
   - **Problema atual**: Editar scorecard for√ßa re-simula√ß√£o completa (2min)
   - **Solu√ß√£o**: Cache invalida√ß√£o seletiva ‚Äî s√≥ re-simula se par√¢metros relevantes mudaram
   - **Ganho esperado**: 50% das edi√ß√µes evitam re-simula√ß√£o
   - **Entreg√°vel**: Sistema de cache com hash de par√¢metros relevantes

3. **Adicionar Simula√ß√µes Incrementais (Mar 2026)**
   - **Problema atual**: Adicionar 1 synth for√ßa re-processar todos os 1.000
   - **Solu√ß√£o**: Executar apenas Œî de synths novos, agregar com resultados anteriores
   - **Ganho esperado**: Adicionar 100 synths leva 10s, n√£o 2min
   - **Entreg√°vel**: API aceita `synth_ids_to_add` em vez de s√≥ `synth_ids`

4. **Otimizar Prompts de LLM (Abr 2026)**
   - **Problema atual**: Prompts de insights t√™m 2K tokens de contexto (80% redundante)
   - **Solu√ß√£o**: Templates concisos, remover exemplos verbosos, usar structured outputs
   - **Ganho esperado**: 2K ‚Üí 800 tokens (60% redu√ß√£o), mantendo qualidade
   - **Entreg√°vel**: A/B test mostrando quality score inalterado com prompts novos

**Crit√©rio de Sucesso**:
- Time-to-Insight mediano < 90min (baseline: 4h)
- Custo por experimento < R$ 15 (baseline: R$ 20)
- Latency p95 de endpoints de IA < 10s (baseline: 30s)

---

#### **Prioridade 3: Construir Feedback Loop com Valida√ß√£o Real**
**Objetivo**: Provar que insights de synths correlacionam com comportamento de usu√°rios reais.

**T√°ticas**:
1. **Feature: "Marcar para Valida√ß√£o" (Mar 2026)**
   - **UX**: Bot√£o em cada insight ‚Äî "Validar com usu√°rios reais"
   - **Backend**: Cria tarefa de valida√ß√£o com checklist (ex: "Recrutar 5 usu√°rios com perfil X", "Executar entrevista", "Comparar resultados")
   - **Objetivo**: Rastrear quais insights foram validados e se confirmaram
   - **Entreg√°vel**: CRUD de validation_tasks + UI de checklist

2. **Coleta de Ground Truth (Abr-Mai 2026)**
   - **A√ß√£o**: Para 10 experimentos de equipes piloto, executar research real ap√≥s synth research
   - **Protocolo**: Mesmo topic guide, mesmas perguntas, compara√ß√£o cega de transcritos
   - **M√©tricas**:
     - % de insights de synths confirmados por humanos
     - % de insights de humanos n√£o previstos por synths (false negatives)
     - Correla√ß√£o de scores quantitativos (success_rate simulado vs. real)
   - **Entreg√°vel**: Paper interno "Validation Study: Synths vs. Humans"

3. **Modelo de Confian√ßa por Tipo de Insight (Jun 2026)**
   - **Input**: Dados de valida√ß√£o (10 experimentos √ó 15 insights avg = 150 datapoints)
   - **An√°lise**: Regress√£o log√≠stica ‚Äî quais tipos de insight t√™m maior precision?
   - **Output**: Badge de confian√ßa (üü¢ alta / üü° m√©dia / üî¥ baixa) em cada insight
   - **Exemplo hipot√©tico**: Insights de SHAP t√™m precision 0.85 ‚Üí üü¢; Insights de outliers t√™m 0.45 ‚Üí üî¥
   - **Entreg√°vel**: Sistema de badges + documenta√ß√£o de metodologia

**Crit√©rio de Sucesso**:
- ‚â• 10 experimentos com valida√ß√£o real completada
- ‚â• 1 artigo/case study public√°vel sobre correla√ß√£o synths vs. humanos
- Sistema de confian√ßa implementado e vis√≠vel no UI

---

#### **Prioridade 4: Posicionamento e Go-to-Market**
**Objetivo**: Definir ICP (Ideal Customer Profile), pricing e canais de aquisi√ß√£o.

**T√°ticas**:
1. **An√°lise de ICP (Jan-Fev 2026)**
   - **Hip√≥tese inicial**: Startups S√©rie A-B, B2C, equipe de produto 5-15 pessoas
   - **Valida√ß√£o**: Entrevistas com 15 PMs/UX Researchers de diferentes perfis
   - **Perguntas**:
     - Quanto tempo/$ gastam em research hoje?
     - Quais decis√µes de produto s√£o mais arriscadas?
     - Pagariam por simula√ß√µes sint√©ticas? Quanto?
   - **Entreg√°vel**: Documento de ICP com 3 personas de clientes

2. **Teste de Pricing (Mar 2026)**
   - **Modelos a testar**:
     - **Freemium**: 5 experimentos/m√™s gr√°tis, $99/m√™s ilimitado
     - **Per-Seat**: $49/m√™s por PM/UX Researcher
     - **Usage-Based**: $5 por experimento (pr√©-pago)
   - **M√©todo**: Van Westendorp Price Sensitivity Meter (survey com 50+ respondentes)
   - **Entreg√°vel**: Recomenda√ß√£o de pricing com modelo financeiro (CAC, LTV, break-even)

3. **Conte√∫do Educacional (Abr-Mai 2026)**
   - **Objetivo**: Educar mercado sobre research sint√©tica (categoria nova)
   - **Formatos**:
     - 3 blog posts t√©cnicos (ex: "Como Simula√ß√µes Monte Carlo Reduzem Risco de Produto")
     - 1 webinar: "De Hip√≥tese a Insights em 2 Horas"
     - 1 case study detalhado com equipe piloto
   - **Distribui√ß√£o**: LinkedIn (org√¢nico), communities de PM (Produto.io, Product Hunt)
   - **Entreg√°vel**: 5 pe√ßas de conte√∫do publicadas, 500+ views agregados

4. **Parceria com Comunidades de Produto (Jun 2026)**
   - **Alvo**: Product Oversee, WomenTech, UXCONF BR
   - **Proposta**: Oferecer acesso gratuito para membros em troca de feedback + case studies
   - **Entreg√°vel**: ‚â• 2 parcerias formalizadas, 50+ usu√°rios adquiridos via comunidades

**Crit√©rio de Sucesso**:
- ICP documentado e validado com ‚â• 10 entrevistas
- Modelo de pricing testado com ‚â• 50 respondentes, recomenda√ß√£o clara
- ‚â• 100 usu√°rios √∫nicos (fora de equipes piloto) testaram produto
- ‚â• 1 case study publicado em comunidade relevante

---

### Roadmap de Features (Pr√≥ximos 6 Meses)

| Feature | Prioridade | Impacto | Esfor√ßo | Prazo |
|---------|-----------|---------|---------|-------|
| **Sistema de Feedback (Thumbs Up/Down)** | P0 | üü¢ Alto (valida√ß√£o de qualidade) | üü° M√©dio (2 semanas) | Jan 2026 |
| **Paraleliza√ß√£o de Insights** | P0 | üü¢ Alto (85% redu√ß√£o lat√™ncia) | üü¢ Baixo (3 dias) | Jan 2026 |
| **Dashboard de M√©tricas de Uso** | P0 | üü¢ Alto (visibilidade de ado√ß√£o) | üü° M√©dio (1 semana) | Fev 2026 |
| **Cache Inteligente de Simula√ß√µes** | P1 | üü° M√©dio (50% menos re-runs) | üü° M√©dio (1.5 semanas) | Fev 2026 |
| **Compara√ß√£o A/B de Experimentos** | P1 | üü° M√©dio (facilita decis√µes) | üü¢ Baixo (4 dias) | Mar 2026 |
| **Valida√ß√£o com Usu√°rios Reais (Tracking)** | P1 | üü¢ Alto (prova de valor) | üî¥ Alto (3 semanas) | Mar 2026 |
| **Badges de Confian√ßa em Insights** | P1 | üü° M√©dio (transpar√™ncia) | üü° M√©dio (1 semana) | Jun 2026 |
| **Multi-Tenancy + Permiss√µes** | P2 | üî¥ Cr√≠tico (blocker p/ B2B) | üî¥ Alto (4 semanas) | Abr 2026 |
| **Exporta√ß√£o de Dados (CSV/JSON)** | P2 | üü° M√©dio (power users) | üü¢ Baixo (2 dias) | Mai 2026 |
| **Integra√ß√£o Jira/Linear** | P3 | üü° M√©dio (workflow) | üü° M√©dio (2 semanas) | Jun 2026 |

---

### Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|--------------|---------|-----------|
| **Equipes piloto n√£o executam experimentos** | üü° M√©dia | üî¥ Alto | Onboarding dedicado (1h/semana), templates prontos, follow-ups semanais |
| **Insights de IA t√™m baixa qualidade (< 50% √∫teis)** | üü° M√©dia | üî¥ Alto | A/B testing de prompts, human-in-the-loop review antes de GA |
| **Valida√ß√£o real contradiz synths sistematicamente** | üü¢ Baixa | üî¥ Alto | Study com 10 experimentos antes de claims p√∫blicos, transpar√™ncia sobre limita√ß√µes |
| **Custos de LLM excedem budget (> R$ 50/exp)** | üü° M√©dia | üü° M√©dio | Otimiza√ß√£o de prompts, cache agressivo, fallback para modelos menores |
| **Concorrente lan√ßa produto similar** | üü° M√©dia | üü° M√©dio | Foco em dados IBGE (moat local), open-source para community lock-in |
| **Churn de equipes piloto (> 50%)** | üü° M√©dia | üü¢ Baixo | NPS surveys mensais, identificar churn signals cedo, oferecer extens√£o gratuita |
| **Escalabilidade: banco de dados n√£o aguenta carga** | üü¢ Baixa | üü° M√©dio | Load testing com 10K synths, 1K experimentos antes de GA, √≠ndices otimizados |

---

### Recursos Necess√°rios

#### **Time (6 meses)**
| Fun√ß√£o | FTE | Justificativa |
|--------|-----|---------------|
| **Backend Engineer** | 1.0 | Features de paraleliza√ß√£o, cache, multi-tenancy |
| **Frontend Engineer** | 0.5 | UI de feedback, dashboards, compara√ß√£o A/B |
| **Product Manager** | 0.3 | Roadmap, prioriza√ß√£o, entrevistas de ICP |
| **UX Researcher (Consultor)** | 0.2 | Desenho de validation studies, an√°lise qualitativa |
| **DevOps/Infra** | 0.1 | Monitoramento, CI/CD, load testing |

#### **Budget (6 meses)**
| Item | Custo | Justificativa |
|------|-------|---------------|
| **LLM API Costs (OpenAI)** | R$ 3.000 | 150 experimentos √ó R$ 20 (buffer 50%) |
| **Infra (AWS/GCP)** | R$ 2.000 | PostgreSQL RDS, compute, storage |
| **Ferramentas (Mixpanel, etc.)** | R$ 1.500 | Analytics, monitoring, CI/CD |
| **Recrutamento de Usu√°rios** | R$ 4.000 | 10 validation studies √ó R$ 400 incentivo |
| **Marketing de Conte√∫do** | R$ 2.500 | Designer, copywriter freelance |
| **Conting√™ncia (20%)** | R$ 2.600 | Buffer para imprevistos |
| **TOTAL** | **R$ 15.600** | ~R$ 2.600/m√™s |

---

## 7. Appendix: Dados e Contexto Adicional

### A. Stack Tecnol√≥gico Completo

#### Backend
```python
Python 3.13+
FastAPI 0.115+          # Web framework
SQLAlchemy 2.0+         # ORM
Pydantic 2.0+           # Data validation
OpenAI SDK 1.57+        # LLM integration
Arize Phoenix           # LLM tracing
OpenTelemetry           # Observability
Alembic                 # Database migrations
PostgreSQL 14+          # Database
Loguru                  # Logging
```

#### Frontend
```typescript
TypeScript 5.5+
React 18
TanStack Query 5        # Server state management
shadcn/ui               # Component library
Tailwind CSS            # Styling
Vite                    # Build tool
```

#### Data Science
```python
NumPy, Pandas           # Data manipulation
Matplotlib, Seaborn     # Visualization
scikit-learn            # Clustering, outlier detection
SHAP                    # Explainability
```

---

### B. Esquema de Banco de Dados (Simplificado)

```sql
-- Core entities
experiments (id, name, hypothesis, scorecard_data JSONB)
synths (id, nome, arquetipo, data JSONB, avatar_path)

-- Quantitative analysis
analysis_runs (id, experiment_id, status, aggregated_outcomes JSONB)
analysis_cache (experiment_id, chart_type, data JSONB)

-- Qualitative research
research_executions (id, topic_name, experiment_id, status, summary_content)
transcripts (id, exec_id, synth_id, messages JSONB[])

-- Scenario exploration
explorations (id, experiment_id, goal, config JSONB, status)
scenario_nodes (id, exploration_id, parent_id, action_applied, scorecard JSONB, simulation_results JSONB)

-- Document management
experiment_documents (id, experiment_id, document_type, content, metadata JSONB)
```

**Relationships**:
- `experiments 1:N analysis_runs` ‚Äî Um experimento pode ter m√∫ltiplas rodadas de simula√ß√£o
- `experiments 1:N research_executions` ‚Äî Um experimento pode ter m√∫ltiplas bateladas de entrevistas
- `research_executions 1:N transcripts` ‚Äî Cada execu√ß√£o gera N transcritos (1 por synth)
- `explorations 1:N scenario_nodes` ‚Äî √Årvore de explora√ß√£o com n√≥s filho
- `experiments 1:N experiment_documents` ‚Äî Documentos gerados (summaries, PR-FAQs)

---

### C. Exemplo de Scorecard (Feature: "Checkout em 1 Clique")

```json
{
  "complexity": {
    "ui_complexity": 3.0,
    "backend_complexity": 7.0,
    "integration_complexity": 6.5
  },
  "effort": {
    "design_effort": 4.0,
    "development_effort": 8.0,
    "testing_effort": 6.0
  },
  "risk": {
    "technical_risk": 5.5,
    "user_adoption_risk": 7.0,
    "security_risk": 8.5
  },
  "time_to_value": {
    "time_to_first_value": 6.0,
    "time_to_full_adoption": 8.0
  }
}
```

**Interpreta√ß√£o**:
- **Complexidade de Backend**: 7.0 (alta) ‚Äî Precisa de tokeniza√ß√£o de cart√£o, PCI compliance
- **Risco de Seguran√ßa**: 8.5 (muito alta) ‚Äî Armazenar dados de pagamento
- **Esfor√ßo de Desenvolvimento**: 8.0 (alto) ‚Äî 4-6 sprints estimados
- **Risco de Ado√ß√£o**: 7.0 (alta) ‚Äî Usu√°rios podem desconfiar de seguran√ßa

Esses valores alimentam o modelo probabil√≠stico:
- `capability = 1 / (1 + complexity_total / 10)` ‚Üí 0.62 (usu√°rio m√©dio tem 62% de capacidade de usar)
- `trust = 1 / (1 + risk_total / 10)` ‚Üí 0.68 (68% de confian√ßa)
- `P(try) = capability √ó trust √ó (1 - friction)` ‚Üí 0.35 (35% tentam usar)

---

### D. Exemplo de Output de Explora√ß√£o

**Experimento**: Dashboard de Analytics (Baseline: 28% success_rate)

**√Årvore de Explora√ß√£o** (beam width = 3, max depth = 5):

```
[ROOT] Baseline (success: 28%)
‚îú‚îÄ [A√ß√£o 1] Remover 40% das m√©tricas menos usadas
‚îÇ  ‚îÇ  Rationale: Reduz cognitive load (complexity 8.5 ‚Üí 5.2)
‚îÇ  ‚îÇ  Result: success 35% (+7pp)
‚îÇ  ‚îú‚îÄ [A√ß√£o 1.1] Adicionar tour guiado interativo
‚îÇ  ‚îÇ  ‚îÇ  Rationale: Aumenta capability (effort 6.0 ‚Üí 7.5, mas trust +2)
‚îÇ  ‚îÇ  ‚îÇ  Result: success 41% (+6pp) ‚≠ê WINNER
‚îÇ  ‚îÇ  ‚îî‚îÄ [A√ß√£o 1.2] Personalizar dashboard por role
‚îÇ  ‚îÇ     ‚îÇ  Result: success 38% (+3pp) [DOMINATED]
‚îÇ  ‚îî‚îÄ [...]
‚îú‚îÄ [A√ß√£o 2] Adicionar presets para casos comuns
‚îÇ  ‚îÇ  Result: success 31% (+3pp) [DOMINATED]
‚îî‚îÄ [A√ß√£o 3] Redesenhar navega√ß√£o com mega-menu
   ‚îÇ  Result: success 29% (+1pp) [DOMINATED]
```

**Caminho Vencedor** (A√ß√£o 1 ‚Üí A√ß√£o 1.1):
1. Remover 40% das m√©tricas (complexity -38%)
2. Adicionar tour guiado (trust +20%, effort +25%)
3. **Resultado final**: 28% ‚Üí 41% success_rate (+46% relativo)

**Resumo Gerado por LLM**:
> "A explora√ß√£o identificou que a sobrecarga cognitiva √© o principal bloqueador de ado√ß√£o. Remover m√©tricas raramente usadas (pageviews por regi√£o, bounce rate por device) reduziu a complexidade percebida sem perda funcional. Adicionar um tour guiado interativo no primeiro acesso compensa o aumento de esfor√ßo ao melhorar a confian√ßa dos usu√°rios de que entendem a ferramenta. O caminho vencedor aumenta a taxa de sucesso de 28% para 41%, tornando a feature vi√°vel para lan√ßamento."

---

### E. Distribui√ß√µes Demogr√°ficas (IBGE)

**Fonte**: Censo 2022 + PNAD Cont√≠nua 2023

| Atributo | Distribui√ß√£o (%) | Fonte |
|----------|------------------|-------|
| **Regi√£o** | Sul 14.3, Sudeste 41.8, Nordeste 27.2, Norte 8.6, Centro-Oeste 8.1 | IBGE Censo 2022 |
| **Faixa Et√°ria** | 18-24 (12%), 25-34 (18%), 35-44 (17%), 45-54 (15%), 55-64 (13%), 65+ (25%) | PNAD 2023 |
| **Renda Familiar** | At√© 2 SM (48%), 2-5 SM (28%), 5-10 SM (14%), 10-20 SM (7%), 20+ SM (3%) | PNAD 2023 |
| **Escolaridade** | Sem instru√ß√£o (6%), Fundamental (32%), M√©dio (43%), Superior (19%) | PNAD 2023 |
| **Defici√™ncias** | Visual (3.4%), Auditiva (1.1%), Motora (2.3%), Cognitiva (0.8%) | Censo 2022 |

**Correla√ß√µes Modeladas**:
- Escolaridade √ó Renda (Pearson r = 0.68)
- Idade √ó Defici√™ncia Motora (r = 0.42 para idade > 55)
- Regi√£o Sul/Sudeste √ó Renda > 5 SM (r = 0.35)

---

### F. Benchmarks de Performance

**Ambiente**: MacBook Pro M2, 16GB RAM, PostgreSQL local

| Opera√ß√£o | Lat√™ncia (p50) | Lat√™ncia (p95) | Throughput |
|----------|----------------|----------------|------------|
| **Gerar 1 Synth** | 12ms | 25ms | 83 synths/s |
| **Gerar Avatar (DALL-E 3)** | 3.2s | 5.1s | 0.3 avatars/s |
| **Simula√ß√£o (1K executions)** | 180ms | 320ms | 5.5 sims/s |
| **Simula√ß√£o (10K executions)** | 1.8s | 2.9s | 0.55 sims/s |
| **Entrevista UX (6 turnos)** | 18s | 35s | 0.055 interviews/s |
| **Insight LLM (1 chart)** | 4.2s | 8.1s | 0.24 insights/s |
| **SHAP Analysis (1K synths)** | 2.1s | 3.4s | 0.47 analyses/s |

**Gargalos Identificados**:
1. **Gera√ß√£o de Avatares**: 90% do tempo de cria√ß√£o de synths (rate limit OpenAI)
2. **Entrevistas UX**: Lat√™ncia dominada por LLM (n√£o paraleliz√°vel dentro de 1 conversa)
3. **SHAP**: Computacionalmente intensivo, n√£o cacheado

---

### G. Gloss√°rio de Termos

| Termo | Defini√ß√£o |
|-------|-----------|
| **Synth** | Synthetic persona ‚Äî personagem simulado com atributos demogr√°ficos, psicogr√°ficos e comportamentais baseados em dados IBGE |
| **Scorecard** | Conjunto de 12 dimens√µes que descrevem uma feature (complexity, effort, risk, time_to_value) |
| **Monte Carlo Simulation** | T√©cnica probabil√≠stica que executa milhares de simula√ß√µes amostrando aleatoriamente da distribui√ß√£o de synths |
| **SHAP (SHapley Additive exPlanations)** | M√©todo de explicabilidade que atribui import√¢ncia a cada feature na predi√ß√£o de um outcome |
| **PDP (Partial Dependence Plot)** | Gr√°fico que mostra o efeito marginal de uma vari√°vel no outcome, mantendo outras constantes |
| **Beam Search** | Algoritmo de busca que mant√©m K candidatos (beam width) em cada n√≠vel da √°rvore de explora√ß√£o |
| **Pareto Dominance** | N√≥ A domina B se A √© melhor ou igual em todas dimens√µes e estritamente melhor em pelo menos uma |
| **Topic Guide** | Roteiro de entrevista UX com perguntas, imagens e documentos de apoio |
| **PR-FAQ** | Press Release + Frequently Asked Questions ‚Äî formato Amazon para especifica√ß√µes de produto |
| **Phoenix Tracing** | Sistema de observabilidade da Arize para rastrear chamadas LLM com spans OpenTelemetry |

---

### H. Refer√™ncias e Links

#### Documenta√ß√£o T√©cnica
- Arquitetura Backend: `/docs/arquitetura.md`
- Arquitetura Frontend: `/docs/arquitetura_front.md`
- Modelo de Dados: `/docs/database_model.md`
- API Reference: `/docs/api.md`

#### Especifica√ß√µes de Features
- `/specs/023-chart-insights.md` ‚Äî Sistema de insights de IA para charts
- `/specs/026-document-management.md` ‚Äî Gerenciamento de documentos
- `/specs/027-postgresql-migration.md` ‚Äî Migra√ß√£o para PostgreSQL
- `/specs/028-exploration-summary.md` ‚Äî Resumos de explora√ß√£o

#### Dados Externos
- IBGE Censo 2022: https://censo2022.ibge.gov.br/
- PNAD Cont√≠nua 2023: https://www.ibge.gov.br/estatisticas/sociais/trabalho/9171-pesquisa-nacional-por-amostra-de-domicilios-continua-mensal.html
- OpenAI API: https://platform.openai.com/docs
- Arize Phoenix: https://docs.arize.com/phoenix

#### Papers de Refer√™ncia
- "Explaining Predictions with SHAP": Lundberg & Lee, 2017
- "Monte Carlo Methods in Financial Engineering": Glasserman, 2003
- "Beam Search Algorithms": Lowerre, 1976

---

**Documento preparado em**: 04 de Janeiro de 2026
**Pr√≥xima revis√£o**: 01 de Abril de 2026 (p√≥s-valida√ß√£o com equipes piloto)
**Respons√°vel**: Fulvio (Product Lead, Synth-Lab)
**Vers√£o**: 1.0
